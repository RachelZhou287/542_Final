{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "https://github.com/RachelZhou287/542_Final/blob/main/BNN.ipynb",
      "authorship_tag": "ABX9TyP/D3rjcP5XMYO7iPUZjyxO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RachelZhou287/542_Final/blob/main/BNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "print(torchvision.__version__)\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader,Dataset\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "#! pip install pyro-ppl\n",
        "import pyro\n",
        "from pyro.distributions import Normal, Categorical\n",
        "from pyro.infer import SVI, Trace_ELBO\n",
        "from pyro.optim import Adam"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxrFjTbgvFeY",
        "outputId": "407ce79b-b188-4340-8d61-9f47386fd29f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.23.0+cu126\n",
            "Collecting pyro-ppl\n",
            "  Downloading pyro_ppl-1.9.1-py3-none-any.whl.metadata (7.8 kB)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.12/dist-packages (from pyro-ppl) (2.0.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from pyro-ppl) (3.4.0)\n",
            "Collecting pyro-api>=0.1.1 (from pyro-ppl)\n",
            "  Downloading pyro_api-0.1.2-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: torch>=2.0 in /usr/local/lib/python3.12/dist-packages (from pyro-ppl) (2.8.0+cu126)\n",
            "Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.12/dist-packages (from pyro-ppl) (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->pyro-ppl) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->pyro-ppl) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->pyro-ppl) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->pyro-ppl) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->pyro-ppl) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->pyro-ppl) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->pyro-ppl) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->pyro-ppl) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->pyro-ppl) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->pyro-ppl) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->pyro-ppl) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->pyro-ppl) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->pyro-ppl) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->pyro-ppl) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->pyro-ppl) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->pyro-ppl) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->pyro-ppl) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->pyro-ppl) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->pyro-ppl) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->pyro-ppl) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->pyro-ppl) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->pyro-ppl) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0->pyro-ppl) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0->pyro-ppl) (3.0.3)\n",
            "Downloading pyro_ppl-1.9.1-py3-none-any.whl (755 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m756.0/756.0 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyro_api-0.1.2-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: pyro-api, pyro-ppl\n",
            "Successfully installed pyro-api-0.1.2 pyro-ppl-1.9.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test integrity first\n",
        "!tar -tzf /content/CUB_200_2011.tgz > /dev/null\n"
      ],
      "metadata": {
        "id": "l8wFtKPDDTgP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract safely\n",
        "!mkdir -p /content/data\n",
        "!tar -xzf /content/CUB_200_2011.tgz -C /content/data/"
      ],
      "metadata": {
        "id": "ZO8rA1WmD0UC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confirm\n",
        "!ls /content/data/CUB_200_2011 | head"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKHEFjlYk5H9",
        "outputId": "19579cd9-4cc4-4af5-a3b5-c3499f92540d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attributes\n",
            "bounding_boxes.txt\n",
            "classes.txt\n",
            "image_class_labels.txt\n",
            "images\n",
            "images.txt\n",
            "parts\n",
            "README\n",
            "train_test_split.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load dataset"
      ],
      "metadata": {
        "id": "P7CaUDjsEHMd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class CUBDataset(Dataset):\n",
        "    def __init__(self, root, train=True, transform=None):\n",
        "        self.root = root\n",
        "        self.transform = transform\n",
        "\n",
        "        img_files = pd.read_csv(os.path.join(root, \"images.txt\"), sep=\" \", names=[\"img_id\", \"filepath\"])\n",
        "        labels = pd.read_csv(os.path.join(root, \"image_class_labels.txt\"), sep=\" \", names=[\"img_id\", \"target\"])\n",
        "        split = pd.read_csv(os.path.join(root, \"train_test_split.txt\"), sep=\" \", names=[\"img_id\", \"is_training_img\"])\n",
        "        df = img_files.merge(labels, on=\"img_id\").merge(split, on=\"img_id\")\n",
        "        df = df[df[\"is_training_img\"] == int(train)]\n",
        "\n",
        "        self.paths = df[\"filepath\"].values\n",
        "        self.targets = df[\"target\"].values - 1  # 0-indexed\n",
        "\n",
        "    def __len__(self):  return len(self.paths) # number of samples\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.root, \"images\", self.paths[idx])\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        label = self.targets[idx]\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, label\n",
        "\n",
        "# === Transforms + loaders ===\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((64,64)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "data_root = \"/content/data/CUB_200_2011\"\n",
        "train_data = CUBDataset(data_root, train=True, transform=transform)\n",
        "test_data  = CUBDataset(data_root, train=False, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=16, shuffle=True, num_workers=2) #batch size: group 32 images per training step\n",
        "test_loader  = DataLoader(test_data, batch_size=16, shuffle=False, num_workers=2)\n",
        "\n",
        "print(f\"✅ Loaded {len(train_data)} training and {len(test_data)} testing images.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2hakI8KEDoV",
        "outputId": "7de6cfa4-b541-4ed0-c73d-7ddb0e2f16a6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Loaded 5994 training and 5794 testing images.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NN Structure"
      ],
      "metadata": {
        "id": "TbmRVx7fGMg3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NN(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size):\n",
        "    super(NN, self).__init__()\n",
        "    self.fc1=nn.Linear(input_size,hidden_size) # y=xW^T+b\n",
        "    self.out=nn.Linear(hidden_size,output_size)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = x.view(x.size(0), -1)\n",
        "    output=self.fc1(x)\n",
        "    output=F.relu(output)\n",
        "    output=self.out(output)\n",
        "    return output # logit prob\n",
        "\n",
        "    log_prob=F.log_softmax(output,dim=1)\n",
        "net=NN(input_size=3*64*64,hidden_size=128,output_size=200) # 200 species in total\n"
      ],
      "metadata": {
        "id": "pSAFDnZfGOlH"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "WHERt1JHK9Xf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model(x_data,y_data):\n",
        "\n",
        "  fc1w_prior=Normal(loc=torch.zeros_like(net.fc1.weight),scale=torch.ones_like(net.fc1.weight)).to_event(2)\n",
        "  fc1b_prior=Normal(loc=torch.zeros_like(net.fc1.bias),scale=torch.ones_like(net.fc1.bias)).to_event(1)\n",
        "\n",
        "  outw_prior=Normal(loc=torch.zeros_like(net.out.weight),scale=torch.ones_like(net.out.weight)).to_event(2)\n",
        "  outb_prior=Normal(loc=torch.zeros_like(net.out.bias),scale=torch.ones_like(net.out.bias)).to_event(1)\n",
        "\n",
        "  priors={'fc1.weight':fc1w_prior,'fc1.bias':fc1b_prior,'out.weight':outw_prior,'out.bias':outb_prior}\n",
        "  lifted_model=pyro.random_module(\"module\",net,priors)\n",
        "  lifted_reg_model=lifted_model() # one regressor model sampling\n",
        "  lhat=log_prob(lifted_reg_model(x_data)) # compute log_probability\n",
        "  pyro.sample(\"obs\", Categorical(logits=lhat), obs=y_data)\n"
      ],
      "metadata": {
        "id": "cfF5uNG2LGc5"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Guide"
      ],
      "metadata": {
        "id": "AV_Aqj7zNJ1x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "softplus = torch.nn.Softplus()\n",
        "\n",
        "def guide(x_data, y_data):\n",
        "\n",
        "    # 1st layer weight\n",
        "    fc1w_mu = torch.randn_like(net.fc1.weight)\n",
        "    fc1w_sigma = torch.randn_like(net.fc1.weight)\n",
        "    fc1w_mu_param = pyro.param(\"fc1w_mu\", fc1w_mu)\n",
        "    fc1w_sigma_param = softplus(pyro.param(\"fc1w_sigma\", fc1w_sigma))\n",
        "    fc1w_prior = Normal(loc=fc1w_mu_param, scale=fc1w_sigma_param)\n",
        "    fc1b_mu = torch.randn_like(net.fc1.bias)\n",
        "    fc1b_sigma = torch.randn_like(net.fc1.bias)\n",
        "    fc1b_mu_param = pyro.param(\"fc1b_mu\", fc1b_mu)\n",
        "    fc1b_sigma_param = softplus(pyro.param(\"fc1b_sigma\", fc1b_sigma))\n",
        "    fc1b_prior = Normal(loc=fc1b_mu_param, scale=fc1b_sigma_param)\n",
        "    # Output layer weight distribution priors\n",
        "    outw_mu = torch.randn_like(net.out.weight)\n",
        "    outw_sigma = torch.randn_like(net.out.weight)\n",
        "    outw_mu_param = pyro.param(\"outw_mu\", outw_mu)\n",
        "    outw_sigma_param = softplus(pyro.param(\"outw_sigma\", outw_sigma))\n",
        "    outw_prior = Normal(loc=outw_mu_param, scale=outw_sigma_param).independent(1)\n",
        "    # Output layer bias distribution priors\n",
        "    outb_mu = torch.randn_like(net.out.bias)\n",
        "    outb_sigma = torch.randn_like(net.out.bias)\n",
        "    outb_mu_param = pyro.param(\"outb_mu\", outb_mu)\n",
        "    outb_sigma_param = softplus(pyro.param(\"outb_sigma\", outb_sigma))\n",
        "    outb_prior = Normal(loc=outb_mu_param, scale=outb_sigma_param)\n",
        "    priors = {'fc1.weight': fc1w_prior, 'fc1.bias': fc1b_prior, 'out.weight': outw_prior, 'out.bias': outb_prior}\n",
        "\n",
        "    lifted_module = pyro.random_module(\"module\", net, priors)\n",
        "\n",
        "    return lifted_module()"
      ],
      "metadata": {
        "id": "PZA0PGHnNJew"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Whole"
      ],
      "metadata": {
        "id": "mjkAt5AGq-nC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.distributions import constraints\n",
        "from pyro.infer import SVI, Trace_ELBO\n",
        "from pyro.optim import Adam\n",
        "import pyro\n",
        "from pyro.distributions import Normal, Categorical\n",
        "\n",
        "\n",
        "# ======================================================\n",
        "# 1️⃣ Define NN architecture\n",
        "# ======================================================\n",
        "class NN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(NN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Flatten 3×128×128 RGB images → [batch, 49152]\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.out(x)  # raw logits (no softmax)\n",
        "        return x\n",
        "\n",
        "\n",
        "# Initialize network\n",
        "input_size = 3 * 64 * 64\n",
        "net = NN(input_size=input_size, hidden_size=128, output_size=200)\n",
        "\n",
        "\n",
        "# ======================================================\n",
        "# 2️⃣ Define Bayesian model\n",
        "# ======================================================\n",
        "def model(x_data, y_data):\n",
        "    # Normal(0,1) priors on all weights and biases\n",
        "    fc1w_prior = Normal(torch.zeros_like(net.fc1.weight),\n",
        "                        torch.ones_like(net.fc1.weight)).to_event(2)\n",
        "    fc1b_prior = Normal(torch.zeros_like(net.fc1.bias),\n",
        "                        torch.ones_like(net.fc1.bias)).to_event(1)\n",
        "    outw_prior = Normal(torch.zeros_like(net.out.weight),\n",
        "                        torch.ones_like(net.out.weight)).to_event(2)\n",
        "    outb_prior = Normal(torch.zeros_like(net.out.bias),\n",
        "                        torch.ones_like(net.out.bias)).to_event(1)\n",
        "\n",
        "    priors = {\n",
        "        'fc1.weight': fc1w_prior,\n",
        "        'fc1.bias': fc1b_prior,\n",
        "        'out.weight': outw_prior,\n",
        "        'out.bias': outb_prior\n",
        "    }\n",
        "\n",
        "    lifted_model = pyro.random_module(\"module\", net, priors)\n",
        "    lifted_reg_model = lifted_model()  # one sample of network parameters\n",
        "\n",
        "    # Forward pass\n",
        "    logits = lifted_reg_model(x_data)\n",
        "\n",
        "    # Each image is an independent observation\n",
        "    with pyro.plate(\"data\", x_data.size(0)):\n",
        "        pyro.sample(\"obs\", Categorical(logits=logits), obs=y_data)\n",
        "\n",
        "\n",
        "# ======================================================\n",
        "# 3️⃣ Define Guide (Variational Posterior)\n",
        "# ======================================================\n",
        "soft_plus = torch.nn.Softplus()\n",
        "\n",
        "def guide(x_data, y_data):\n",
        "    # Layer 1 weight posterior\n",
        "    fc1w_mu = pyro.param(\"fc1w_mu\", torch.randn_like(net.fc1.weight))\n",
        "    fc1w_sigma_param = pyro.param(\"fc1w_sigma\", torch.ones_like(net.fc1.weight))\n",
        "    fc1w_sigma = soft_plus(fc1w_sigma_param)\n",
        "    fc1w_dist = Normal(fc1w_mu, fc1w_sigma).to_event(2)\n",
        "\n",
        "    # Layer 1 bias posterior\n",
        "    fc1b_mu = pyro.param(\"fc1b_mu\", torch.randn_like(net.fc1.bias))\n",
        "    fc1b_sigma_param = pyro.param(\"fc1b_sigma\", torch.ones_like(net.fc1.bias))\n",
        "    fc1b_sigma = soft_plus(fc1b_sigma_param)\n",
        "    fc1b_dist = Normal(fc1b_mu, fc1b_sigma).to_event(1)\n",
        "\n",
        "    # Output layer weight posterior\n",
        "    outw_mu = pyro.param(\"outw_mu\", torch.randn_like(net.out.weight))\n",
        "    outw_sigma_param = pyro.param(\"outw_sigma\", torch.ones_like(net.out.weight))\n",
        "    outw_sigma = soft_plus(outw_sigma_param)\n",
        "    outw_dist = Normal(outw_mu, outw_sigma).to_event(2)\n",
        "\n",
        "    # Output layer bias posterior\n",
        "    outb_mu = pyro.param(\"outb_mu\", torch.randn_like(net.out.bias))\n",
        "    outb_sigma_param = pyro.param(\"outb_sigma\", torch.ones_like(net.out.bias))\n",
        "    outb_sigma = soft_plus(outb_sigma_param)\n",
        "    outb_dist = Normal(outb_mu, outb_sigma).to_event(1)\n",
        "\n",
        "    dists = {\n",
        "        'fc1.weight': fc1w_dist,\n",
        "        'fc1.bias': fc1b_dist,\n",
        "        'out.weight': outw_dist,\n",
        "        'out.bias': outb_dist\n",
        "    }\n",
        "\n",
        "    lifted_module = pyro.random_module(\"module\", net, dists)\n",
        "    return lifted_module()\n",
        "\n",
        "\n",
        "# ======================================================\n",
        "# 4️⃣ Training Loop (SVI)\n",
        "# ======================================================\n",
        "pyro.clear_param_store()\n",
        "\n",
        "optimizer = Adam({\"lr\": 0.01})\n",
        "svi = SVI(model, guide, optimizer, loss=Trace_ELBO())\n",
        "\n",
        "num_epochs = 5\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0.0\n",
        "    for batch_id, (x, y) in enumerate(train_loader):\n",
        "        x = x.view(x.size(0), -1)  # Flatten\n",
        "        y = y.long()               # Ensure class indices\n",
        "        loss = svi.step(x, y)\n",
        "        total_loss += loss\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader.dataset)\n",
        "    print(f\"Epoch {epoch+1} - Loss: {avg_loss:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6M3ytoYlhJl",
        "outputId": "778a698c-6690-43b9-a8f0-a94769f9eca3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pyro/primitives.py:526: FutureWarning: The `random_module` primitive is deprecated, and will be removed in a future release. Use `pyro.nn.Module` to create Bayesian modules from `torch.nn.Module` instances.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 - Loss: 21723.0462\n"
          ]
        }
      ]
    }
  ]
}