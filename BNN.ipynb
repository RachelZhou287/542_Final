{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "https://github.com/RachelZhou287/542_Final/blob/main/BNN.ipynb",
      "authorship_tag": "ABX9TyNoV3TwsaqX/nN7smXrWxzb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RachelZhou287/542_Final/blob/main/BNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "print(torchvision.__version__)\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader,Dataset\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "#! pip install pyro-ppl\n",
        "import pyro\n",
        "from pyro.distributions import Normal, Categorical\n",
        "from pyro.infer import SVI, Trace_ELBO\n",
        "from pyro.optim import Adam\n",
        "import pyro.poutine as poutine"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxrFjTbgvFeY",
        "outputId": "c89009fd-126f-4eab-ba1b-e3f507ecc7e0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.23.0+cu126\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test integrity first\n",
        "!tar -tzf /content/CUB_200_2011.tgz > /dev/null\n"
      ],
      "metadata": {
        "id": "l8wFtKPDDTgP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract safely\n",
        "!mkdir -p /content/data\n",
        "!tar -xzf /content/CUB_200_2011.tgz -C /content/data/"
      ],
      "metadata": {
        "id": "ZO8rA1WmD0UC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confirm\n",
        "!ls /content/data/CUB_200_2011 | head"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKHEFjlYk5H9",
        "outputId": "19579cd9-4cc4-4af5-a3b5-c3499f92540d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attributes\n",
            "bounding_boxes.txt\n",
            "classes.txt\n",
            "image_class_labels.txt\n",
            "images\n",
            "images.txt\n",
            "parts\n",
            "README\n",
            "train_test_split.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load dataset"
      ],
      "metadata": {
        "id": "P7CaUDjsEHMd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class CUBDataset(Dataset):\n",
        "    def __init__(self, root, train=True, transform=None):\n",
        "        self.root = root\n",
        "        self.transform = transform\n",
        "\n",
        "        img_files = pd.read_csv(os.path.join(root, \"images.txt\"), sep=\" \", names=[\"img_id\", \"filepath\"])\n",
        "        labels = pd.read_csv(os.path.join(root, \"image_class_labels.txt\"), sep=\" \", names=[\"img_id\", \"target\"])\n",
        "        split = pd.read_csv(os.path.join(root, \"train_test_split.txt\"), sep=\" \", names=[\"img_id\", \"is_training_img\"])\n",
        "        df = img_files.merge(labels, on=\"img_id\").merge(split, on=\"img_id\")\n",
        "        df = df[df[\"is_training_img\"] == int(train)]\n",
        "\n",
        "        self.paths = df[\"filepath\"].values\n",
        "        self.targets = df[\"target\"].values - 1  # 0-indexed\n",
        "\n",
        "    def __len__(self):  return len(self.paths) # number of samples\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.root, \"images\", self.paths[idx])\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        label = self.targets[idx]\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, label\n",
        "\n",
        "# === Transforms + loaders ===\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((64,64)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "data_root = \"/content/data/CUB_200_2011\"\n",
        "train_data = CUBDataset(data_root, train=True, transform=transform)\n",
        "test_data  = CUBDataset(data_root, train=False, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=16, shuffle=True, num_workers=2) #batch size: group 32 images per training step\n",
        "test_loader  = DataLoader(test_data, batch_size=16, shuffle=False, num_workers=2)\n",
        "\n",
        "print(f\"✅ Loaded {len(train_data)} training and {len(test_data)} testing images.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2hakI8KEDoV",
        "outputId": "7de6cfa4-b541-4ed0-c73d-7ddb0e2f16a6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Loaded 5994 training and 5794 testing images.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NN Structure"
      ],
      "metadata": {
        "id": "TbmRVx7fGMg3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(NN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Flatten 3×128×128 RGB images → [batch, 49152]\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.out(x)  # raw logits (no softmax)\n",
        "        return x\n",
        "\n",
        "\n",
        "# Initialize network\n",
        "input_size = 3 * 64 * 64\n",
        "net = NN(input_size=input_size, hidden_size=128, output_size=200)"
      ],
      "metadata": {
        "id": "pSAFDnZfGOlH"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "WHERt1JHK9Xf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model(x_data, y_data):\n",
        "    # Normal(0,1) priors on all weights and biases\n",
        "    fc1w_prior = Normal(torch.zeros_like(net.fc1.weight),\n",
        "                        torch.ones_like(net.fc1.weight)).to_event(2)\n",
        "    fc1b_prior = Normal(torch.zeros_like(net.fc1.bias),\n",
        "                        torch.ones_like(net.fc1.bias)).to_event(1)\n",
        "    outw_prior = Normal(torch.zeros_like(net.out.weight),\n",
        "                        torch.ones_like(net.out.weight)).to_event(2)\n",
        "    outb_prior = Normal(torch.zeros_like(net.out.bias),\n",
        "                        torch.ones_like(net.out.bias)).to_event(1)\n",
        "\n",
        "    priors = {\n",
        "        'fc1.weight': fc1w_prior,\n",
        "        'fc1.bias': fc1b_prior,\n",
        "        'out.weight': outw_prior,\n",
        "        'out.bias': outb_prior\n",
        "    }\n",
        "\n",
        "    lifted_model = pyro.random_module(\"module\", net, priors)\n",
        "    lifted_reg_model = lifted_model()  # one sample of network parameters\n",
        "\n",
        "    # Forward pass\n",
        "    logits = lifted_reg_model(x_data)\n",
        "\n",
        "    # Each image is an independent observation\n",
        "    with pyro.plate(\"data\", x_data.size(0)):\n",
        "        pyro.sample(\"obs\", Categorical(logits=logits), obs=y_data)"
      ],
      "metadata": {
        "id": "cfF5uNG2LGc5"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Guide"
      ],
      "metadata": {
        "id": "AV_Aqj7zNJ1x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "soft_plus = torch.nn.Softplus()\n",
        "\n",
        "def guide(x_data, y_data):\n",
        "    # Layer 1 weight posterior\n",
        "    fc1w_mu = pyro.param(\"fc1w_mu\", torch.randn_like(net.fc1.weight))\n",
        "    fc1w_sigma_param = pyro.param(\"fc1w_sigma\", torch.ones_like(net.fc1.weight))\n",
        "    fc1w_sigma = soft_plus(fc1w_sigma_param)\n",
        "    fc1w_dist = Normal(fc1w_mu, fc1w_sigma).to_event(2)\n",
        "\n",
        "    # Layer 1 bias posterior\n",
        "    fc1b_mu = pyro.param(\"fc1b_mu\", torch.randn_like(net.fc1.bias))\n",
        "    fc1b_sigma_param = pyro.param(\"fc1b_sigma\", torch.ones_like(net.fc1.bias))\n",
        "    fc1b_sigma = soft_plus(fc1b_sigma_param)\n",
        "    fc1b_dist = Normal(fc1b_mu, fc1b_sigma).to_event(1)\n",
        "\n",
        "    # Output layer weight posterior\n",
        "    outw_mu = pyro.param(\"outw_mu\", torch.randn_like(net.out.weight))\n",
        "    outw_sigma_param = pyro.param(\"outw_sigma\", torch.ones_like(net.out.weight))\n",
        "    outw_sigma = soft_plus(outw_sigma_param)\n",
        "    outw_dist = Normal(outw_mu, outw_sigma).to_event(2)\n",
        "\n",
        "    # Output layer bias posterior\n",
        "    outb_mu = pyro.param(\"outb_mu\", torch.randn_like(net.out.bias))\n",
        "    outb_sigma_param = pyro.param(\"outb_sigma\", torch.ones_like(net.out.bias))\n",
        "    outb_sigma = soft_plus(outb_sigma_param)\n",
        "    outb_dist = Normal(outb_mu, outb_sigma).to_event(1)\n",
        "\n",
        "    dists = {\n",
        "        'fc1.weight': fc1w_dist,\n",
        "        'fc1.bias': fc1b_dist,\n",
        "        'out.weight': outw_dist,\n",
        "        'out.bias': outb_dist\n",
        "    }\n",
        "\n",
        "    lifted_module = pyro.random_module(\"module\", net, dists)\n",
        "    return lifted_module()\n"
      ],
      "metadata": {
        "id": "_smNJWr7sK00"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Whole"
      ],
      "metadata": {
        "id": "mjkAt5AGq-nC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.distributions import constraints\n",
        "from pyro.infer import SVI, Trace_ELBO\n",
        "from pyro.optim import Adam\n",
        "import pyro\n",
        "from pyro.distributions import Normal, Categorical\n",
        "\n",
        "\n",
        "# ======================================================\n",
        "# 1️⃣ Define NN architecture\n",
        "# ======================================================\n",
        "class NN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(NN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Flatten 3×128×128 RGB images → [batch, 49152]\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.out(x)  # raw logits (no softmax)\n",
        "        return x\n",
        "\n",
        "\n",
        "# Initialize network\n",
        "input_size = 3 * 64 * 64\n",
        "net = NN(input_size=input_size, hidden_size=128, output_size=200)\n",
        "\n",
        "\n",
        "# ======================================================\n",
        "# 2️⃣ Define Bayesian model\n",
        "# ======================================================\n",
        "def model(x_data, y_data):\n",
        "    # Normal(0,1) priors on all weights and biases\n",
        "    fc1w_prior = Normal(torch.zeros_like(net.fc1.weight),\n",
        "                        torch.ones_like(net.fc1.weight)).to_event(2)\n",
        "    fc1b_prior = Normal(torch.zeros_like(net.fc1.bias),\n",
        "                        torch.ones_like(net.fc1.bias)).to_event(1)\n",
        "    outw_prior = Normal(torch.zeros_like(net.out.weight),\n",
        "                        torch.ones_like(net.out.weight)).to_event(2)\n",
        "    outb_prior = Normal(torch.zeros_like(net.out.bias),\n",
        "                        torch.ones_like(net.out.bias)).to_event(1)\n",
        "\n",
        "    priors = {\n",
        "        'fc1.weight': fc1w_prior,\n",
        "        'fc1.bias': fc1b_prior,\n",
        "        'out.weight': outw_prior,\n",
        "        'out.bias': outb_prior\n",
        "    }\n",
        "\n",
        "    lifted_model = pyro.random_module(\"module\", net, priors)\n",
        "    lifted_reg_model = lifted_model()  # one sample of network parameters\n",
        "\n",
        "    # Forward pass\n",
        "    logits = lifted_reg_model(x_data)\n",
        "\n",
        "    # Each image is an independent observation\n",
        "    with pyro.plate(\"data\", x_data.size(0)):\n",
        "        pyro.sample(\"obs\", Categorical(logits=logits), obs=y_data)\n",
        "\n",
        "\n",
        "# ======================================================\n",
        "# 3️⃣ Define Guide (Variational Posterior)\n",
        "# ======================================================\n",
        "soft_plus = torch.nn.Softplus()\n",
        "\n",
        "def guide(x_data, y_data):\n",
        "    # Layer 1 weight posterior\n",
        "    fc1w_mu = pyro.param(\"fc1w_mu\", torch.randn_like(net.fc1.weight))\n",
        "    fc1w_sigma_param = pyro.param(\"fc1w_sigma\", torch.ones_like(net.fc1.weight))\n",
        "    fc1w_sigma = soft_plus(fc1w_sigma_param)\n",
        "    fc1w_dist = Normal(fc1w_mu, fc1w_sigma).to_event(2)\n",
        "\n",
        "    # Layer 1 bias posterior\n",
        "    fc1b_mu = pyro.param(\"fc1b_mu\", torch.randn_like(net.fc1.bias))\n",
        "    fc1b_sigma_param = pyro.param(\"fc1b_sigma\", torch.ones_like(net.fc1.bias))\n",
        "    fc1b_sigma = soft_plus(fc1b_sigma_param)\n",
        "    fc1b_dist = Normal(fc1b_mu, fc1b_sigma).to_event(1)\n",
        "\n",
        "    # Output layer weight posterior\n",
        "    outw_mu = pyro.param(\"outw_mu\", torch.randn_like(net.out.weight))\n",
        "    outw_sigma_param = pyro.param(\"outw_sigma\", torch.ones_like(net.out.weight))\n",
        "    outw_sigma = soft_plus(outw_sigma_param)\n",
        "    outw_dist = Normal(outw_mu, outw_sigma).to_event(2)\n",
        "\n",
        "    # Output layer bias posterior\n",
        "    outb_mu = pyro.param(\"outb_mu\", torch.randn_like(net.out.bias))\n",
        "    outb_sigma_param = pyro.param(\"outb_sigma\", torch.ones_like(net.out.bias))\n",
        "    outb_sigma = soft_plus(outb_sigma_param)\n",
        "    outb_dist = Normal(outb_mu, outb_sigma).to_event(1)\n",
        "\n",
        "    dists = {\n",
        "        'fc1.weight': fc1w_dist,\n",
        "        'fc1.bias': fc1b_dist,\n",
        "        'out.weight': outw_dist,\n",
        "        'out.bias': outb_dist\n",
        "    }\n",
        "\n",
        "    lifted_module = pyro.random_module(\"module\", net, dists)\n",
        "    return lifted_module()\n",
        "\n",
        "\n",
        "# ======================================================\n",
        "# 4️⃣ Training Loop (SVI)\n",
        "# ======================================================\n",
        "pyro.clear_param_store()\n",
        "\n",
        "optimizer = Adam({\"lr\": 0.01})\n",
        "svi = SVI(model, guide, optimizer, loss=Trace_ELBO())\n",
        "\n",
        "num_epochs = 5\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0.0\n",
        "    for batch_id, (x, y) in enumerate(train_loader):\n",
        "        x = x.view(x.size(0), -1)  # Flatten\n",
        "        y = y.long()               # Ensure class indices\n",
        "        loss = svi.step(x, y)\n",
        "        total_loss += loss\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader.dataset)\n",
        "    print(f\"Epoch {epoch+1} - Loss: {avg_loss:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6M3ytoYlhJl",
        "outputId": "778a698c-6690-43b9-a8f0-a94769f9eca3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pyro/primitives.py:526: FutureWarning: The `random_module` primitive is deprecated, and will be removed in a future release. Use `pyro.nn.Module` to create Bayesian modules from `torch.nn.Module` instances.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 - Loss: 21723.0462\n",
            "Epoch 2 - Loss: 1300.5110\n",
            "Epoch 3 - Loss: 566.7162\n",
            "Epoch 4 - Loss: 570.2169\n",
            "Epoch 5 - Loss: 589.0503\n"
          ]
        }
      ]
    }
  ]
}